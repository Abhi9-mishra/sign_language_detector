# ğŸ§  Sign Language Detector ğŸ¤Ÿ (Real-time using Mediapipe + CNN)

A real-time Sign Language Detection web application built using **Python**, **Mediapipe**, **OpenCV**, and **CNN (Keras/TensorFlow)**. This project detects hand gestures via webcam and classifies them into corresponding ASL (American Sign Language) alphabets.

---

## ğŸ”§ Tech Stack

- ğŸ Python
- ğŸ“¹ OpenCV
- âœ‹ MediaPipe (Hand Landmarks)
- ğŸ¤– TensorFlow + Keras (CNN Model)
- ğŸ§  NumPy, Pandas
- ğŸ“Š Matplotlib (for visualization)

---

## ğŸ“¦ Features

- âœ… Real-time webcam input for hand gesture detection
- âœ… 21-point hand landmark detection via MediaPipe
- âœ… CNN trained on gesture keypoints to recognize ASL alphabets
- âœ… Instant letter prediction shown on-screen
- âœ… Smooth UI using OpenCV window display

---

## ğŸ“ Project Structure

```bash
sign_language_detector/
â”‚
â”œâ”€â”€ data_collection/           # Collect gesture data from webcam
â”‚   â””â”€â”€ collect_data.py
â”‚
â”œâ”€â”€ model_training/            # Train CNN on keypoints
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ sign_model.h5          # Trained model
â”‚
â”œâ”€â”€ detection_app/             # Run real-time detection
â”‚   â””â”€â”€ detect_sign.py
â”‚
â”œâ”€â”€ utils/                     # Helper files (keypoint extraction, plotting)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

